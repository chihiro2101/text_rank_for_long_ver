so , in the context of program optimization , there are two main strategies to handle computationally undecidable analysis : an optimizer that is expected to complete in a relatively short amount of time , such as the optimizer in an optimizing compiler , may use a truncated version of an analysis that is guaranteed to complete in a finite amount of time , and guaranteed to only find correct optimizations an optimizing compiler is at liberty to generate code that does anything at runtime even crashes if it encounters source code whose semantics are unspecified by the language standard in use the purpose of control-flow analysis is to obtain information about which functions can be called at various points during the execution of a program one of the most known examples of data-flow analysis is taint checking which consists of considering all variables which contain user supplied data which is considered '' tainted '' , i.e abstract interpretation allows the extraction of information about a possible execution of a program without actually executing the program this information can be used by compilers to look for possible optimizations or for certifying a program against certain classes of bugs dynamic analysis can use runtime knowledge of the program to increase the precision of the analysis , while also providing runtime protection , but it can only analyze a single execution of the problem and might degrade the program ’ s performance due to the runtime checks software should be tested to ensure its quality and that it performs as it is supposed to in a reliable manner , and that it won ’ t create conflicts with other software that may function alongside it even if no security requirements are specified , additional security testing should be performed to ensure that an attacker can ’ t tamper with the software and steal information , disrupt the software ’ s normal operations , or use it as a pivot to attack its users 