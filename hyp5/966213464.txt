futurebus looked to fix these problems and create a successor to systems like vmebus with a system that could grow in speed without affecting existing devices in order to do this the primary technology of futurebus was built using asynchronous links , allowing the devices plugged into it to talk at whatever speed they wished another problem that needed to be addressed was the ability to have several cards in the system as '' masters '' , allowing futurebus to build multiprocessor machines this required some form of '' distributed arbitration '' to allow the various cards to gain access to the bus at any point , as opposed to vme , which put a single master in slot 0 with overall control american logic machines ( alm ) continues to build end to end system futurebus hybrid solutions , including vme-to-futurebus+ and other bus-to-futurebus bridge technologies that was just in time for the us navy who had been looking for a new high-speed system for the next generation computer resources ( ngcr ) project for passing sonar data around in their newly designed seawolf-class submarine , and they said they would standardize on futurebus if only a few more changes would be made boards that were compliant with one futurebus+ profile were not guaranteed to work with boards built to a different profile the decade-long performance gap they gave the system had evaporated in the decade-long standards process , and conventional local bus systems like pci were close in performance terms vme and other parallel bus standards are still trying to adapt concepts that are implemented in the futurebus , specially in high performance applications many of the technical features ( asynchronous data bus , distributed bus arbitration , large board size ) are shared with ieee standard fastbus futurebus+ was one of the first open standards to support live insertion which allowed boards to be replaced while the system was running 