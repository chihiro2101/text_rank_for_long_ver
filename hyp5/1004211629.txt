in a shared memory multiprocessor system with a separate cache memory for each processor , it is possible to have many copies of shared data : one copy in the main memory and one in the local cache of each processor that requested it ; transaction serialization : reads/writes to a single memory location must be seen by all processors in the same order one type of data occurring simultaneously in different cache memory is called cache coherence , or in some systems , global memory in a multiprocessor system , consider that more than one processor has cached a copy of the memory location x therefore , in order to satisfy transaction serialization , and hence achieve cache coherence , the following condition along with the previous two mentioned in this section must be met : writes to the same location must be sequenced the alternative definition of a coherent system is via the definition of sequential consistency memory model : '' the cache coherent system must appear to execute all threads â€™ loads and stores to a single memory location in a total order that respects the program order of each thread '' thus , the only difference between the cache coherent system and sequentially consistent system is in the number of address locations the definition talks about ( single memory location for a cache coherent system , and all memory locations for a sequentially consistent system ) multiple copies of same data can exist in different cache simultaneously and if processors are allowed to update their own copies freely , an inconsistent view of memory can result every request must be broadcast to all nodes in a system , meaning that as the system gets larger , the size of the ( logical or physical ) bus and the bandwidth it provides must grow distributed shared memory systems mimic these mechanisms in an attempt to maintain consistency between blocks of memory in loosely coupled systems typically , early systems used directory-based protocols where a directory would keep a track of the data being shared and the sharers write propagation in snoopy protocols can be implemented by either of the following methods : ; write-invalidate : when a write operation is observed to a location that a cache has a copy of , the cache controller invalidates its own copy of the snooped memory location , which forces a read from main memory of the new value on its next access if the protocol design states that whenever any copy of the shared data is changed , all the other copies must be '' updated '' to reflect the change , then it is a write-update protocol 