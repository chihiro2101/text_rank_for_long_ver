a rete-based expert system builds a network of nodes , where each node ( except the root ) corresponds to a pattern occurring in the left-hand-side ( the condition part ) of a rule as new facts are asserted or modified , they propagate along the network , causing nodes to be annotated when that fact matches that pattern in most cases , the speed increase over na√Øve implementations is several orders of magnitude ( because rete performance is theoretically independent of the number of rules in the system ) in very large expert systems , however , the original rete algorithm tends to run into memory and server consumption problems the rete algorithm provides a generalized logical description of an implementation of functionality responsible for matching data tuples ( '' facts '' ) against productions ( '' rules '' ) in a pattern-matching production system ( a category of rule engine ) the rete algorithm exhibits the following major characteristics : it reduces or eliminates certain types of redundancy through the use of node sharing this , in turn , allows production systems to avoid complete re-evaluation of all facts each time changes are made to the production system 's working memory it provides a means for many-many matching , an important feature when many or all possible solutions in a search network must be found the '' left '' ( alpha ) side of the node graph forms a discrimination network responsible for selecting individual wmes based on simple conditional tests which match wme attributes against constant values nodes in the discrimination network may also perform tests that compare two or more attributes of the same wme in most engines , the immediate child nodes of the root node are used to test the entity identifier or fact type of each wme hence , all the wmes which represent the same entity type typically traverse a given branch of nodes in the discrimination network wmes that fail to match at least one condition in a branch are not materialised within the corresponding alpha memory in descriptions of rete , it is common to refer to token passing within the beta network in this article , however , we will describe data propagation in terms of wme lists , rather than tokens , in recognition of different implementation options and the underlying purpose and use of tokens when a join node is left-activated it traverses a single newly stored wme list in the beta memory , retrieving specific attribute values of given wmes other engines allow beta nodes to take input directly from two alpha memories , treating one as a '' left '' input and the other as a '' right '' input as well as join nodes , the beta network may contain additional node types , some of which are described below during any one match-resolve-act cycle , the engine will find all possible matches for the facts currently asserted to working memory once all the current matches have been found , and corresponding production instances have been activated on the agenda , the engine determines an order in which the production instances may be '' fired '' the order may be based on rule priority ( salience ) , rule order , the time at which facts contained in each instance were asserted to the working memory , the complexity of each production , or some other criteria the engine undertakes matching of the changed data which , in turn , may result in changes to the list of production instances on the agenda some engines support advanced refraction strategies in which certain production instances executed in a previous cycle are not re-executed in the new cycle , even though they may still exist on the agenda they may also provide automatic loop detection in which never-ending loops are automatically halted after a given number of iterations however , by implementing additional beta node types , it is possible for rete networks to perform quantifications universal quantification involves testing that an entire set of wmes in working memory meets a given condition in another approach , the node maintains an additional memory on each wme list received from the left input the second approach described above is often used to support efficient mechanisms for removal of wme lists , intensive use of beta join nodes ) , or , for some engines , when executing rules sets that perform a significant number of wme retractions during multiple match-resolve-act cycles thumb most implementations use type nodes to perform the first level of selection on n-tuple working memory elements for a more detailed and complete description of the rete algorithm , see chapter 2 of production matching for large learning systems by robert doorenbos ( see link below ) a possible variation is to introduce additional memories for each intermediate node in the discrimination network when a wme enters the rete , the index is used to locate a set of memories whose conditional pattern matches the wme attributes , and the wme is then added directly to each of these memories however , in order to implement non-equality tests , the rete may contain additional 1-input node networks through which wmes are passed before being placed in a memory in many implementations , tokens are introduced within alpha memories where they are used to hold single wmes each beta node performs its work and , as a result , may create new tokens to hold a list of wmes representing a partial match in this case , the beta nodes typically pass lists of wmes through the beta network by copying existing wme lists from each received token into new tokens and then adding further wmes to the lists as a result of performing a join or some other action although not defined by the rete algorithm , some engines provide extended functionality to support greater control of truth maintenance justification refers to mechanisms commonly required in expert and decision systems in which , at its simplest , the system reports each of the inner decisions used to reach some final conclusion for example , engines may provide specialised support within the rete network in order to apply pattern-matching rule processing to specific data types and sources such as programmatic objects , xml data or table ( database ) another example concerns additional time-stamping facilities provided by many engines for each wme entering a rete network , and the use of these time-stamps in conjunction with conflict resolution strategies engines exhibit significant variation in the way they allow programmatic access to the engine and its working memory , and may extend the basic rete model to support forms of parallel and distributed processing several of these , however , apply only in very specific scenarios , and therefore often have little or no application in a general-purpose rules engine performance of rete is also largely a matter of implementation choices ( independent of the network topology ) , one of which ( the use of hash tables ) leads to major improvements to mention only a frequent bias and an unfair type of comparison : 1 ) the use of toy problems such as the manners and waltz examples ; such examples are useful to estimate specific properties of the implementation , but they may not reflect real performance on complex applications ; 2 ) the use of an old implementation ; for instance , the references in the following two sections ( rete ii and rete-nt ) compare some commercial products to totally outdated versions of clips and they claim that the commercial products may be orders of magnitude faster than clips ; this is forgetting that clips 6.30 ( with the introduction of hash tables as in rete ii ) is orders of magnitude faster than the version used for the comparisons ( clips 6.04 ) rete ii can be characterized by two areas of improvement ; specific optimizations relating to the general performance of the rete network ( including the use of hashed memories in order to increase performance with larger sets of data ) , and the inclusion of a backward chaining algorithm tailored to run on top of the rete network 